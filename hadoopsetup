#!/bin/bash
# This is a nondestructive script which can be run many times without banging on the files adding the 
# same info again and again. I is designed for 64 bit ubuntu
# Do not put a "/" at the end of paths!

#Variables START HERE
#Hadoop User
HADOOPUSER="hduser"
HADOOPGRP="hadoop"
# Password only used if not passed in as arg on commandline.
HADOOPPASS="password"


# Hadoop
HADOOPVER=hadoop-2.4.0

#Java 
JAVA_REQ_VER="1.7.0_55"

#NFS
NFSLOCALMNT="/mnt/share"
NFSSERVERMNT="192.168.0.10:/share"
FSTABSTR="${NFSSERVERMNT}      ${NFSLOCALMNT}    nfs async,nfsvers=3,actimeo=0,tcp,rsize=32768,wsize=32768    0       0"


#Common HOSTS file
SUBNET=255.255.255.0
HOSTFILE=hosts
SLAVEFILE=slaves
REMOTEHOSTDIR=/mnt/share/hadoop/other
LOCALHOSTDIR=/etc
HOSTNAME=`hostname`
DOMAIN="tux.localdomain"
IPADDRESS=`ifconfig | sed -n "/inet addr:.*${SUBNET}/{s/.*inet addr://; s/ .*//; p}"`
HOSTENTRY="$IPADDRESS   $HOSTNAME.$DOMAIN   $HOSTNAME" 
#Variables STOP HERE


# must be root
if [[ $EUID -ne 0 ]]; then
   echo "This script must be run as root" 1>&2
   exit 1
fi

# install some required packages
apt-get -qq update > /dev/null
apt-get install -y -qq screen openssh-server nfs-common rsync 

# purge open java
apt-get -y purge openjdk-\* icedtea-\* icedtea6-\* > /dev/null


# mount nfs
echo "[INFO]   NFS" 1>&2
# create nfs mount for zotac
if [ ! -d ${NFSLOCALMNT} ]; then
   mkdir -p ${NFSLOCALMNT}
   echo "[INFO]   Created ${NFSLOCALMNT}" 1>&2
else
   echo "[INFO]   ${NFSLOCALMNT} exits" 1>&2
fi
grep "${NFSSERVERMNT}" /etc/fstab >/dev/null  || echo ${FSTABSTR} >> /etc/fstab 
mount -a

#setup hadoop user, use 1st arg supplied on cli, but if empty, use the variable set at the top of script.
echo "[INFO]   HADOOP USER AND GROUP" 1>&2
if [ -z "$1" ] ; then
   ARGPASS=${HADOOPPASS}
   echo "[INFO]   Using Pass from script" 1>&2
else
   ARGPASS=$1
   echo "[INFO]   Using Pass from argument passed to script" 1>&2
fi 

addgroup ${HADOOPGRP}
PASS=`perl -e "print crypt($ARGPASS, $ARGPASS);"`
useradd -d /home/${HADOOPUSER} -m ${HADOOPUSER} -p "$PASS" -G ${HADOOPGRP},sudo -s /bin/bash

# setup ssh (yes this is bad)
echo "[INFO]   SSH" 1>&2
cd /mnt/share/hadoop/other
tar vxzf ssh.gz -C /home/hduser

# copy hadoop 
echo "[INFO]   DOWNLOAD HADOOP ${HADOOPVER}" 1>&2
if [ ! -d "/usr/local/hadoop" ]; then
tar xzf /mnt/share/hadoop/hadoop/${HADOOPVER}.tar.gz -C /usr/local
cd /usr/local
mv ${HADOOPVER} hadoop
chown -R ${HADOOPUSER}:${HADOOPGRP} hadoop
echo "[INFO]  Copied hadoop" 1>&2
else
echo "[INFO]  Hadoop folder already exists - delete /usr/local/hadoop to re-install" 1>&2
fi

# copy java  if not setup already.
echo "[INFO]   JAVA" 1>&2
if [ ! -d "/usr/local/java" ]; then
   mkdir -p "/usr/local/java"
   echo "[INFO]   Created /usr/local/java" 1>&2
fi

JAVA_VER=$(java -version 2>&1 | sed 's#java version "\(.*\)\(.*\)\.*"#\1\2#; 1q')
echo "[INFO]  Local java is ${JAVA_VER}"
echo "[INFO]  Required java is ${JAVA_REQ_VER}"
if [ ${JAVA_VER} != ${JAVA_REQ_VER} ]; then
  echo "[INFO]  Updateing java to ${JAVA_REQ_VER}"
  sleep 5s
  cp -r  /mnt/share/hadoop/java/64/jdk1.7.0_55/ /usr/local/java/
  cd /usr/local/java
  # configure java
  update-alternatives --install "/usr/bin/java" "java" "/usr/local/java/jdk1.7.0_55/bin/java" 1
  update-alternatives --install "/usr/bin/javac" "javac" "/usr/local/java/jdk1.7.0_55/bin/javac" 1
  update-alternatives --install "/usr/bin/javaws" "javaws" "/usr/local/java/jdk1.7.0_55/bin/javaws" 1
  update-alternatives --install "/usr/bin/jps" "jps" "/usr/local/java/jdk1.7.0_55/bin/jps" 1
  update-alternatives --set java /usr/local/java/jdk1.7.0_55/bin/java
  update-alternatives --set javac /usr/local/java/jdk1.7.0_55/bin/javac
  update-alternatives --set javaws /usr/local/java/jdk1.7.0_55/bin/javaws
  update-alternatives --set jps /usr/local/java/jdk1.7.0_55/bin/jps
  chmod a+x /usr/bin/java
  chmod a+x /usr/bin/javac
  chmod a+x /usr/bin/javaws
  chmod a+x /usr/bin/jps
else
echo "[INFO]   No changes to java required" 1>&2
fi
sleep 5s

## setup environment variables
echo "[INFO]   ENVIRONMENT AND BASH" 1>&2
profile_file=/home/${HADOOPUSER}/.bashrc
if ! grep -q '#Hadoop variables' "${profile_file}" ; then
echo "[INFO]   Patching .bashrc" 1>&2
cat >> ${profile_file} << EOF
#Hadoop variables
export JAVA_HOME=/usr/local/java/jdk1.7.0_55/
export HADOOP_INSTALL=/usr/local/hadoop
export PATH=$PATH:$HADOOP_INSTALL/bin
export PATH=$PATH:$HADOOP_INSTALL/sbin
export HADOOP_MAPRED_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_HOME=$HADOOP_INSTALL
export HADOOP_HDFS_HOME=$HADOOP_INSTALL
export YARN_HOME=$HADOOP_INSTALL
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_INSTALL/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_INSTALL/lib"
#end of paste
EOF
echo "[INFO] Updated .bashrc for hadoop variables" 1>&2
source /home/${HADOOPUSER}/.bashrc
chown ${HADOOPUSER}:${HADOOPGRP} /home/${HADOOPUSER}/.bashrc
else
echo "[INFO]  Skipping .bashrc update" 1>&2
fi

# configure hadoop
cd /usr/local/hadoop/etc/hadoop
if [ ! -f "updated" ]; then
touch mapred-site.xml
touch hdfs-site.xml
touch yarn-site.xml
mv hdfs-site.xml hdfs-site.xml.old
mv mapred-site.xml mapred-site.xml.old
mv yarn-site.xml yarn-site.xml.old
cp /mnt/share/hadoop/other/hdfs-site.xml .
cp /mnt/share/hadoop/other/mapred-site.xml .
cp /mnt/share/hadoop/other/yarn-site.xml .
touch updated
echo "[INFO]  Updated hdfs,yarn,mapred files"
else
echo "[INFO]  ''updated'' file found - no changes made to hdfs,yarn,mapred files"
fi
yes | cp /mnt/share/hadoop/other/slaves .
chown -R ${HADOOPUSER}:${HADOOPGRP} .


## update a central hosts file (not using DNS) All hadoop masters and slaves grab a common host file.
# you may need to update the subnet mask to reflect your network structure.
echo "[INFO]   PATCH HOSTS" 1>&2
if ! grep -q ${HOSTNAME} ${REMOTEHOSTDIR}/${HOSTFILE} ; then
   echo ${HOSTENTRY} >> ${REMOTEHOSTDIR}/${HOSTFILE}
   echo "[INFO]  Added new entry for ${HOSTNAME} into ${HOSTFILE}" 1>&2
fi

if ! grep -q ${HOSTNAME} ${REMOTEHOSTDIR}/${SLAVEFILE} ; then
   echo ${HOSTNAME} >> ${REMOTEHOSTDIR}/${SLAVEFILE}
   echo "[INFO]  Added new entry for ${HOSTNAME} into ${SLAVEFILE}" 1>&2
fi


# pull down and overwrite current host file.
# then append "localhost" to the relevent entry
mv ${LOCALHOSTDIR}/${HOSTFILE} ${LOCALHOSTDIR}/${HOSTFILE}.old
cp ${REMOTEHOSTDIR}/${HOSTFILE} ${LOCALHOSTDIR}/${HOSTFILE}
sed -i "s#^${HOSTENTRY}#${HOSTENTRY}  localhost#" ${LOCALHOSTDIR}/${HOSTFILE}

## Update cron to pull central hosts file.
# use 1 file for hosts and pull it often using cron. We also need to add localhost to the right entry.
#CRON="1 2 3 4 5 /root/bin/backup.sh"
#cat < (crontab -l) |grep -v "${CRON}" < (echo "${CRON}")
